{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fetch_data.ipynb","provenance":[{"file_id":"1E5_kONUvTczADxMkPXW6tG9fkH6vqSIb","timestamp":1624344696501}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"code","metadata":{"id":"284i5tSq8Uer"},"source":["!pip install pandas\n","!pip install requests"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ui-uCTtqHq18"},"source":["import pandas as pd\n","import requests\n","import os\n","import json\n","import time\n","import objectpath\n","from datetime import datetime, timedelta\n","import random\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNKoWZz17CQ8"},"source":["ROOT_FOLDER = './'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qt2YIgqJNUqZ"},"source":["# To set your environment variables in your terminal run the following line:\n","# export 'BEARER_TOKEN'='<your_bearer_token>'\n","bearer_token = \"\" # fill token here\n","\n","search_url = \"https://api.twitter.com/2/tweets/search/all\"\n","\n","\n","def create_headers(bearer_token):\n","    \"\"\"\n","    Create headers for api query\n","    \"\"\"\n","    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n","    return headers\n","\n","def create_params(query, start_time, end_time, next_token=None):\n","    \"\"\"\n","    Create parameters for api query\n","    \"\"\"\n","    # Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n","    # expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n","    query_params = {}\n","    query_params['query'] = query\n","    query_params['expansions'] = 'geo.place_id,author_id'\n","    query_params['start_time'] = start_time\n","    query_params['end_time'] = end_time\n","    query_params['user.fields'] = 'id,username,verified,public_metrics,created_at'\n","    query_params['tweet.fields'] = 'created_at,public_metrics'\n","    query_params['max_results'] = 100\n","    if next_token:\n","        query_params['next_token'] = next_token\n","    return query_params\n","\n","def parse_response(res):\n","    \"\"\"\n","    Parse the response from the Twitter API\n","    \"\"\"\n","    df = pd.DataFrame()\n","    next_token = None\n","    data = res['data'] if 'data' in res else {}\n","    includes = res['includes'] if 'includes' in res else {}\n","    meta = res['meta']\n","\n","    for d in data:\n","        dic = {'author_id': d['author_id'],'tweet_id': d['id'],'text': d['text'], 'like_count': d['public_metrics']['like_count'],\n","                                  'quote_count': d['public_metrics']['quote_count'], 'retweet_count': d['public_metrics']['retweet_count'],\n","                                  'tweet_created_at': d['created_at']}\n","        tree_obj = objectpath.Tree(includes)\n","        user_data = tree_obj.execute(\"$.users[@.id is '{}']\".format(d['author_id']))\n","        entry = next(user_data)\n","        dic['user_created_at'] = entry['created_at']\n","        dic['username'] = entry['username']\n","        dic['following_count'] = entry['public_metrics']['following_count']\n","        dic['listed_count'] = entry['public_metrics']['listed_count']\n","        dic['tweet_count'] = entry['public_metrics']['tweet_count']\n","        dic['user_verified'] = entry['verified']\n","        df = df.append(pd.Series(dic), ignore_index=True)\n","    if df.shape[0] > 0:\n","        df.drop_duplicates('tweet_id', inplace=True)\n","        df.drop(df.loc[df['tweet_id'].isin(all_tweet_ids)].index, inplace=True)\n","        all_tweet_ids.extend(df['tweet_id'].tolist())\n","    if 'next_token' in meta:\n","        next_token = meta['next_token']\n","    return df, next_token\n","\n","def connect_to_endpoint(url, headers, params):\n","    \"\"\"\n","    Establish connection to the Twitter API\n","    \"\"\"\n","    response = requests.request(\"GET\", search_url, headers=headers, params=params)\n","    if response.status_code != 200:\n","        raise Exception(response.status_code, response.text)\n","    return response.json()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgRHEp80HyzU"},"source":["countries = {'AE' : 'United Arab Emirates', 'BH' : 'Bahrain', 'JO' : 'Jordan', 'LB': 'Lebanon',\n","            'MA' : 'Morocco',  'SA' : 'Saudi Arabia', 'TR' : 'Turkey', 'EG':'Egypt', 'IL': 'Israel'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPIEovKZ5JaT"},"source":["query_words = ['israel', 'gaza', 'jerusalem', 'palestine', 'palestinians', 'hamas', 'rockets', \n","                        'el kuds', 'iron dome', 'israelUnderFire', 'SaveSheikhJarrah', 'gazzaUnderAttack', \n","                        'israelUnderAttack', 'FreePalestine', 'Gaza_Under_Attack', 'SaveAlAqsaMosque']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IxQvjgXR228n"},"source":["query_params = {\n","    'before':{\n","        'start_time' : '2021-04-28T00:00:00Z',\n","        'end_time' : '2021-05-09T23:59:59Z',\n","        },    \n","    'during':{\n","        'start_time' : '2021-05-10T00:00:00Z',\n","        'end_time' : '2021-05-21T23:59:59Z',\n","        },\n","    'after':{\n","        'start_time' : '2021-05-22T00:00:00Z',\n","        'end_time' : '2021-06-04T23:59:59Z',\n","        }\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LJkRqSutOiHl","scrolled":false},"source":["all_tweet_ids = []\n","for (c_shortcut, c_fullname), (_, pop_ratio) in zip(countries.items(), countries_pop.items()):\n","    print('Country: {}'.format(c_fullname))\n","    \n","    query = '(' + ' OR '.join(query_words) + ') place_country:{}'\n","    query = query.format(c_shortcut)\n","    for period_type, period_values in query_params.items():\n","        print('Started \\\"{}\\\" period'.format(period_type))\n","        header = True\n","        output_file = os.path.join(ROOT_FOLDER, 'data', c_fullname + '_' + period_type + '.csv')\n","    \n","        while next_token is not None:\n","            next_token = None\n","            params = create_params(query, start_time, end_time, next_token)\n","            time.sleep(5)\n","            headers = create_headers(bearer_token)\n","            json_response = connect_to_endpoint(search_url, headers, params)\n","            df, next_token = parse_response(json_response)\n","            df.to_csv(output_file, index=False, header=header, mode='a')\n","            header = False\n","            \n","        end_time_log = time.time()\n","        print('Finished \\\"{}\\\" period in {} minutes'.format(period_type, str((end_time_log-start_time_log)/60)))\n","    print('Finished: {}'.format(c_fullname))"],"execution_count":null,"outputs":[]}]}